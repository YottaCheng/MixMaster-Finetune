import os
import re
import json
import random
from docx import Document
from typing import List, Dict, Tuple
from collections import OrderedDict


class Config:
    # è·¯å¾„é…ç½®
    input_file = '/Volumes/Study/prj/data/raw/training_labeled_data.docx'
    output_file = '/Volumes/Study/prj/data/llama_factory/test_back.json'
    
    # æ ‡ç­¾é…ç½®
    label_mapping = OrderedDict([
        ("é«˜é¢‘", "high_freq"),
        ("ä¸­é¢‘", "mid_freq"),
        ("ä½é¢‘", "low_freq"),
        ("å‹ç¼©", "compression"),
        ("å£°åœº", "soundstage"),
        ("reverb", "reverb"),
        ("éŸ³é‡", "volume"),
        ("æ•ˆæœ", "effect")
    ])
    
    # ç½®ä¿¡åº¦ç”Ÿæˆè§„åˆ™ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
    confidence_rules = {
        "high_freq": (0.7, 0.95),    # é«˜é¢‘å¤„ç†ç½®ä¿¡åº¦èŒƒå›´
        "mid_freq": (0.6, 0.85),     # ä¸­é¢‘å¤„ç†èŒƒå›´
        "low_freq": (0.5, 0.75),
        "compression": (0.65, 0.9),
        "soundstage": (0.7, 0.95),
        "reverb": (0.75, 1.0),
        "volume": (0.8, 1.0),
        "effect": (0.5, 0.8)
    }
    
    # ç³»ç»Ÿæç¤ºæ¨¡æ¿
    system_prompt = """æ‚¨æ˜¯ä¸€ä¸ªä¸“ä¸šéŸ³ä¹åˆ¶ä½œåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·å¯¹éŸ³é¢‘æ•ˆæœçš„æè¿°ï¼Œä»ä»¥ä¸‹æ ‡ç­¾ä¸­é€‰æ‹©åˆé€‚çš„å¤„ç†æ–¹å¼..."""
    
    # éšæœºé…ç½®
    random_seed = 42
    test_ratio = 1.0

class DataConverter:
    def __init__(self):
        self.counter = 0
        random.seed(Config.random_seed)
        
    def _generate_confidence(self, label: str) -> float:
        """ç”Ÿæˆæ ‡ç­¾ç½®ä¿¡åº¦"""
        min_val, max_val = Config.confidence_rules.get(label, (0.5, 1.0))
        return round(random.uniform(min_val, max_val), 2)
        
    def process_line(self, line: str) -> Dict:
        """å¤„ç†å•è¡Œæ•°æ®ï¼ˆå«å…ƒæ•°æ®ç”Ÿæˆï¼‰"""
        self.counter += 1
        
        # æå–åŸºç¡€ä¿¡æ¯
        parts = re.split(r'[ï¼ˆï¼‰]', line)
        if len(parts) < 2:
            return None
            
        text = re.sub(r'^\d+\.\s*', '', parts[0]).strip()
        raw_labels = [lbl.strip() for lbl in re.split(r'[ï¼Œ,ã€]', parts[1])]
        
        # æ ‡ç­¾å¤„ç†
        label_confidences = {}
        for lbl in raw_labels:
            if mapped := Config.label_mapping.get(lbl):
                confidence = self._generate_confidence(mapped)
                label_confidences[mapped] = confidence
                
        if not label_confidences:
            return None
            
        # æ„å»ºmetadata
        metadata = {
            "text_length": len(text),
            "label_confidence": label_confidences,
            "label_count": len(label_confidences)
        }
        
        return {
            "id": f"mix_{self.counter:04d}",
            "conversations": [
                {
                    "role": "user",
                    "content": f"{Config.system_prompt}\né—®é¢˜ï¼š{text}"
                },
                {
                    "role": "assistant",
                    "content": ",".join(sorted(label_confidences.keys()))
                }
            ],
            "metadata": metadata
        }

    def generate_testset(self, data: List[Dict]) -> List[Dict]:
        """ç”Ÿæˆå…¨é‡æµ‹è¯•é›†"""
        random.shuffle(data)
        return data[:int(len(data)*Config.test_ratio)]
    def parse_docx(self, file_path: str) -> List[str]:
        """è§£æWordæ–‡æ¡£ï¼Œè¿”å›éç©ºæ®µè½åˆ—è¡¨"""
        doc = Document(file_path)
        lines = []
        for para in doc.paragraphs:
            text = para.text.strip()
            if text:
                lines.append(text)
        return lines    

# =====================
# ä¸»ç¨‹åº
# =====================
def main():
    # åˆå§‹åŒ–è½¬æ¢å™¨
    converter = DataConverter()
    
    try:
        # 1. è¯»å–æ•°æ®
        if not os.path.exists(Config.input_file):
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {Config.input_file}")
            
        raw_lines = converter.parse_docx(Config.input_file)
        print(f"âœ… æˆåŠŸè¯»å– {len(raw_lines)} æ¡åŸå§‹æ•°æ®")

        # 2. å¤„ç†æ•°æ®
        processed_data = []
        for line in raw_lines:
            if item := converter.process_line(line):
                processed_data.append(item)
        print(f"ğŸ”„ æœ‰æ•ˆè½¬æ¢ {len(processed_data)} æ¡æ•°æ®ï¼ˆè¿‡æ»¤ {len(raw_lines)-len(processed_data)} æ¡æ— æ•ˆæ•°æ®ï¼‰")

        # 3. ç”Ÿæˆæµ‹è¯•é›†
        test_data = converter.generate_testset(processed_data)
        
        # 4. ä¿å­˜ç»“æœ
        os.makedirs(os.path.dirname(Config.output_file), exist_ok=True)
        with open(Config.output_file, 'w', encoding='utf-8') as f:
            json.dump(test_data, f, ensure_ascii=False, indent=2)
            
        print(f"ğŸ’¾ å·²ç”Ÿæˆæµ‹è¯•é›†ï¼š{len(test_data)} æ¡ â†’ {Config.output_file}")

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
        exit(1)

if __name__ == "__main__":
    main()