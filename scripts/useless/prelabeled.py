import os
import re
import time
import random
import numpy as np
import requests
import os
from dashscope import api_key
from typing import List, Dict
from docx import Document
from docx.shared import Pt
from collections import defaultdict
import dashscope
from dashscope import Generation
import pandas as pd 
from concurrent.futures import ThreadPoolExecutor, as_completed
from tenacity import retry, stop_after_attempt, wait_exponential
from snorkel.labeling import PandasLFApplier
from snorkel.labeling import LabelingFunction
from snorkel.labeling.model import LabelModel

# é…ç½®ä¿¡æ¯ï¼ˆå·²æ›´æ–°APIä¿¡æ¯ï¼‰
CONFIG = {
    "api_key": "sk-3511f72cb3324a36b42ac8dc91568769",  
    "base_url":"https://dashscope.aliyuncs.com/compatible-mode/v1",
    "model": "deepseek-r1",
    "input_path": "/Volumes/Study/prj/data/processed/filtered_results.docx",
    "output_path": "/Volumes/Study/prj/data/raw/training_labeled_data.docx",
    "auto_save_interval": 50,
    "label_rules": {
        "é«˜é¢‘": ["æ˜äº®", "é½¿éŸ³", "ç©ºæ°”æ„Ÿ", "å¹²å‡€"],
        "ä¸­é¢‘": ["äººå£°åšåº¦", "é¼»éŸ³", "æµ‘æµŠæ„Ÿ", "é¥±å’Œæ„Ÿ"],
        "ä½é¢‘": ["Basså¹³è¡¡", "åšé‡æ„Ÿ", "ä½é¢‘"],
        "å‹ç¼©": ["åŠ¨æ€æ§åˆ¶", "å¥å¤´", "å¥å°¾"],
        "reverb": ["ç©ºé—´æ„Ÿ", "ç¯å¢ƒæ•ˆæœ", "æ··å“"],
        "å£°åœº": ["å®½åº¦", "å®šä½", "ç«‹ä½“æ„Ÿ"],
        "éŸ³é‡": ["ç”µå¹³è°ƒæ•´", "éŸ³é‡"],
        "æ•ˆæœå™¨": ["autotune","ç”µè¯éŸ³","å¤±çœŸ"]
    },
    "conflict_rules": [
        (["é«˜é¢‘", "ä½é¢‘"], 0.3),
        (["å‹ç¼©", "reverb"], 0.5)
    ],
    "gen_model_params": {
        "epochs": 100,
        "lr": 0.01,
        "metric": "f1"
    },
    "verify_per_label": 1
}

class AudioPreLabelSystem:
    @retry(stop=stop_after_attempt(3), 
          wait=wait_exponential(multiplier=1, min=2, max=10))
    def __init__(self):
        dashscope.api_key = CONFIG["api_key"]
        dashscope.base_url = CONFIG["base_url"]  # ç¡®ä¿base_urlæ­£ç¡®
        
        # ä¿®æ”¹æµ‹è¯•è¯·æ±‚
        try:
            test_response = Generation.call(
                model=CONFIG["model"],  # ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹åç§°
                messages=[{"role": "user", "content": "test"}],
                result_format='message',  # æ·»åŠ å¿…è¦å‚æ•°
                timeout=5
            )
            if test_response.status_code == 200:
                print("âœ… APIè¿æ¥æµ‹è¯•é€šè¿‡")
            else:
                raise Exception(f"æµ‹è¯•å¤±è´¥: {test_response.message}")
        except Exception as e:
            print(f"âŒ APIè¿æ¥å¤±è´¥: {str(e)}")
            exit(1)
        
        print("ğŸ”„ åˆå§‹åŒ–æ ‡æ³¨å‡½æ•°...")
        self.lfs = self._init_labeling_functions()
        print(f"âœ… å·²åŠ è½½ {len(self.lfs)} ä¸ªæ ‡æ³¨å‡½æ•°")
        
        print("ğŸ”„ åˆå§‹åŒ–ç”Ÿæˆæ¨¡å‹...")
        self.label_model = LabelModel(cardinality=len(CONFIG["label_rules"]))
        print("âœ… ç”Ÿæˆæ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        
        self.L_train = None
        self.samples = []
        self.verified_data = []
        self.label_stats = defaultdict(int)
        self.start_time = time.time()
        self.applier = PandasLFApplier(lfs=self.lfs)


    def _init_labeling_functions(self):
        """ä¿®æ­£é—­åŒ…é—®é¢˜å’ŒAPIå‡½æ•°ä½ç½®"""
        lfs = []
        
        # ä¿®æ­£å…³é”®å­—è§„åˆ™é—­åŒ…
        for label, keywords in CONFIG["label_rules"].items():
            def make_kw_lf(l=label, kws=keywords):  # âœ… å›ºåŒ–å˜é‡
                def lf_func(x):
                    return l if any(kw in x.text for kw in kws) else -1
                return LabelingFunction(name=f"kw_{l}", f=lf_func)
            lfs.append(make_kw_lf())
        
        # è½¬æ¢æ­£åˆ™è§„åˆ™
        regex_rules = [
            (r'å¤ªäº®|åˆºè€³', 'é«˜é¢‘'),
            (r'é—·|ä¸æ¸…æ™°', 'ä¸­é¢‘'),
            (r'è½°|éœ‡', 'ä½é¢‘')
        ]
        for pattern, label in regex_rules:
            def make_re_lf(p=pattern, l=label):   # ç»‘å®šå½“å‰å€¼
                def lf_func(x):
                    return l if re.search(p, x.text) else -1
                return LabelingFunction(name=f"re_{l}", f=lf_func)
            lfs.append(make_re_lf())
        
        
        
        # æ·»åŠ APIå¼±ç›‘ç£
        def api_lf(x):
            labels = self._call_deepseek(x.text)
            return labels[0] if labels else -1
        lfs.append(LabelingFunction(name="api_weak", f=api_lf))
        
        return lfs

    class TextWrapper:
        """é€‚é…åŸæœ‰æ–‡æœ¬æ ¼å¼åˆ°Snorkel"""
        def __init__(self, text: str):
            self.text = text

    def _train_generative_model(self, texts: List[str]):
        from tqdm import tqdm
        
        print(f"\nğŸ”„ å¼€å§‹ç”Ÿæˆå¼±ç›‘ç£æ ‡ç­¾ï¼ˆå…±{len(texts)}æ¡ï¼‰")
        with tqdm(total=len(texts), desc="ç”Ÿæˆè¿›åº¦") as pbar:
            with ThreadPoolExecutor(max_workers=5) as executor:
                futures = {executor.submit(self.applier.apply, pd.DataFrame({"text": [text]})): text for text in texts}
                results = []
                for future in as_completed(futures):
                    results.extend(future.result())
                    pbar.update(1)
                self.L_train = np.array(results)
        for i, future in enumerate(as_completed(futures)):
            results.extend(future.result())
            pbar.update(1)
            
            # æ–°å¢è‡ªåŠ¨ä¿å­˜é€»è¾‘
            if (i+1) % CONFIG["auto_save_interval"] == 0:
                self._save_checkpoint(results, i+1)

    def _custom_analysis_report(self):
        """è‡ªå®šä¹‰æ ‡æ³¨å‡½æ•°è´¨é‡åˆ†æ"""
        print("\n=== æ ‡æ³¨å‡½æ•°è´¨é‡åˆ†æ ===")
        coverage = (self.L_train != -1).mean(axis=0)
        conflicts = (self.L_train[:, None] != self.L_train) & (self.L_train != -1)
        
        print(f"{'å‡½æ•°åç§°':<20} | {'è¦†ç›–ç‡':<10} | {'å†²çªç‡':<10}")
        print("-" * 50)
        for i, lf in enumerate(self.lfs):
            conflict_rate = conflicts[:, i].mean()
            print(f"{lf.name:<20} | {coverage[i]:<10.2%} | {conflict_rate:<10.2%}")

    def _call_deepseek(self, text: str) -> List[str]:
        """ä¿®æ­£åçš„APIè°ƒç”¨æ–¹æ³•"""
        prompt = f"""ä½œä¸ºä¸“ä¸šæ··éŸ³å¸ˆï¼Œè¯·å°†ä»¥ä¸‹éœ€æ±‚è½¬æ¢ä¸ºæ ‡å‡†æ ‡ç­¾ï¼š
å¯é€‰æ ‡ç­¾ï¼š{", ".join(CONFIG['label_rules'].keys())}
è¾“å…¥æè¿°ï¼š{text}
åªéœ€è¿”å›é€—å·åˆ†éš”çš„æ ‡ç­¾åˆ—è¡¨ï¼Œä¸è¦å…¶ä»–å†…å®¹"""
        
        try:
            response = Generation.call(
                model=CONFIG["model"],  # ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹åç§°
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                top_p=0.7,
                max_tokens=50,
                result_format='message',  # å¿…é¡»å‚æ•°
                timeout=15
            )
            
            # ä¿®æ­£å“åº”è§£æé€»è¾‘
            if response.status_code == 200:
                content = response.output.choices[0].message.content
                return [
                    label.strip()
                    for label in content.split(",")
                    if label.strip() in CONFIG["label_rules"]
                ][:3]
            else:
                print(f"APIé”™è¯¯: {response.code} - {response.message}")
                return []
                

        except Exception as e:
            print(f"â€¼ï¸ APIè¯·æ±‚å¤±è´¥è¯¦æƒ…ï¼š")
            print(f"URL: {dashscope.base_url}")
            print(f"Model: deepseek-chat")
            print(f"Error: {str(e)}")
            print(f"è¯·æ±‚å†…å®¹: {text[:50]}...")  # æ˜¾ç¤ºéƒ¨åˆ†è¾“å…¥å†…å®¹
            return []
        
    def _load_input(self) -> List[str]:
        """ä¿æŒåŸæœ‰æ•°æ®åŠ è½½é€»è¾‘"""
        try:
            doc = Document(CONFIG["input_path"])
            return [para.text.strip() for para in doc.paragraphs if para.text.strip()]
        except Exception as e:
            print(f"æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
            exit(1)

    def _save_output(self, probs: np.ndarray = None):
        """å¢å¼ºä¿å­˜é€»è¾‘ï¼ˆä¿æŒåŸæœ‰æ ¼å¼ï¼‰"""
        doc = Document()
        style = doc.styles['Normal']
        style.font.name = 'å¾®è½¯é›…é»‘'
        style.font.size = Pt(11)

        line_num = 1
        for idx, item in enumerate(self.verified_data):
            text = item['text']
            labels = item['labels']
            
            # æ·»åŠ æ¦‚ç‡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            prob_info = ""
            if probs is not None:
                top_probs = sorted(zip(CONFIG["label_rules"].keys(), probs[idx]), 
                               key=lambda x: x[1], reverse=True)[:3]
                prob_info = " | ".join([f"{k}:{v:.2f}" for k,v in top_probs])
            
            p = doc.add_paragraph(f"{line_num}. {text}")
            p.add_run(f"ï¼ˆ{', '.join(labels)} {prob_info}ï¼‰").bold = True
            line_num += 1
        
        os.makedirs(os.path.dirname(CONFIG["output_path"]), exist_ok=True)
        doc.save(CONFIG["output_path"])
        print(f"\nå·²ä¿å­˜é¢„æ ‡æ³¨ç»“æœåˆ°ï¼š{CONFIG['output_path']}")

    def manual_verification(self):
        """å…¨æ–°éªŒè¯æµç¨‹"""
        label_map = defaultdict(list)
        for sample in self.samples:
            for label in sample['labels']:
                label_map[label].append(sample)
        
        # é¦–è½®éªŒè¯ï¼šæ¯ç±»æŠ½1ä¸ªæ ·æœ¬
        verify_samples = []
        for label in CONFIG["label_rules"].keys():
            samples = label_map.get(label, [])
            if samples:
                verify_samples.append(random.choice(samples))
        
        print(f"\n{'='*50}")
        print(f"å¼€å§‹æ ‡ç­¾æŠ½æ ·éªŒè¯ï¼ˆå…±{len(verify_samples)}ä¸ªæ ·æœ¬ï¼‰")
        
        for idx, sample in enumerate(verify_samples, 1):
            print(f"\nã€éªŒè¯è¿›åº¦ {idx}/{len(verify_samples)}ã€‘")
            print(f"åŸå§‹æè¿°ï¼š{sample['text']}")
            print(f"å½“å‰æ ‡ç­¾ï¼š{', '.join(sample['labels'])}")
            action = input("æ˜¯å¦æ¥å—ï¼Ÿ(y/n/e): ").strip().lower()
            
            if action == 'e':
                self._edit_labels(sample)
            elif action == 'y':
                self.verified_data.append(sample)
        
        # è‡ªåŠ¨æ¥å—æœªéªŒè¯æ ·æœ¬
        auto_accept = [s for s in self.samples 
                       if not any(s['text'] == v['text'] for v in self.verified_data)]
        self.verified_data.extend(auto_accept)
        
        self._show_statistics()
    def _save_checkpoint(self, results, processed_num):
        checkpoint_path = os.path.join(os.path.dirname(CONFIG["output_path"]), "checkpoint.pkl")
        with open(checkpoint_path, 'wb') as f:
            pickle.dump({
                'processed_num': processed_num,
                'results': results,
                'timestamp': time.time()
            }, f)
        print(f"\nğŸ”” å·²ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆå·²å¤„ç†{processed_num}æ¡ï¼‰")
        
    def run(self):
        """å¢å¼ºåçš„ä¸»æµç¨‹"""
        try:
            # é˜¶æ®µ1ï¼šæ•°æ®åŠ è½½
            raw_texts = self._load_input()
            
            # é˜¶æ®µ2ï¼šè®­ç»ƒç”Ÿæˆæ¨¡å‹
            self._train_generative_model(raw_texts)
            
            # é˜¶æ®µ3ï¼šç”Ÿæˆæ¦‚ç‡æ ‡ç­¾
            probs = self._generate_probs()
            
            # é˜¶æ®µ4ï¼šç”Ÿæˆåˆå§‹æ ‡æ³¨
            self.samples = [{
                'text': text,
                'labels': [list(CONFIG["label_rules"].keys())[np.argmax(p)]],
                'prob': max(p)
            } for text, p in zip(raw_texts, probs)]
            
            # é˜¶æ®µ5ï¼šäººå·¥éªŒè¯ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            self.manual_verification()
            
            # é˜¶æ®µ6ï¼šä¿å­˜ç»“æœï¼ˆå¢å¼ºè¾“å‡ºï¼‰
            self._save_output(probs)
            self._show_statistics()

        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­æ“ä½œï¼Œæ­£åœ¨ä¿å­˜å·²éªŒè¯æ•°æ®...")
            self._save_output()
            self._show_statistics()



    def _show_statistics(self):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        self.label_stats = defaultdict(int)
        for sample in self.verified_data:
            for label in sample['labels']:
                self.label_stats[label] += 1
        
        print("\n" + "="*50)
        print(f"æ€»è€—æ—¶ï¼š{time.time()-self.start_time:.2f}ç§’")
        print(f"æ€»æ ·æœ¬æ•°ï¼š{len(self.verified_data)}")
        for label, count in self.label_stats.items():
            print(f"{label}ï¼š{count}æ¡")

    def _edit_labels(self, sample: dict):
        """ç¼–è¾‘æ ‡ç­¾"""
        new_labels = []
        print(f"å½“å‰æ ‡ç­¾ï¼š {sample['labels']}")
        #print("å¯ç”¨æ ‡ç­¾ï¼š", ", ".join(self.prelabeler.label_rules.keys()))
        print("å¯ç”¨æ ‡ç­¾ï¼š", ", ".join(CONFIG["label_rules"].keys()))  # âœ… ç›´æ¥ä½¿ç”¨CONFIG
        valid_labels = [l for l in input_labels if l in CONFIG["label_rules"]]
        
        while True:
            input_labels = input("è¯·è¾“å…¥æ­£ç¡®æ ‡ç­¾ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰: ").split()
            valid_labels = [l for l in input_labels if l in self.prelabeler.label_rules]
            
            if valid_labels:
                sample['labels'] = valid_labels[:3]  # æ›´æ–°æ ‡ç­¾å¹¶é™åˆ¶æœ€å¤š3ä¸ª
                self.verified_data.append(sample)
                print(f"âœ“ å·²æ›´æ–°ä¸ºï¼š{valid_labels}")
                break
            print("åŒ…å«æ— æ•ˆæ ‡ç­¾ï¼Œè¯·é‡æ–°è¾“å…¥ï¼")
    def _generate_probs(self):  # æ·»åŠ ç¼ºå¤±æ–¹æ³•
        """ç”Ÿæˆæ¦‚ç‡æ ‡ç­¾"""
        return self.label_model.predict_proba(self.L_train)   

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨éŸ³é¢‘é¢„æ ‡æ³¨ç³»ç»Ÿ")
    system = AudioPreLabelSystem()
    
    try:
        print("\n=== é˜¶æ®µ1ï¼šæ•°æ®åŠ è½½ ===")
        raw_texts = system._load_input()
        print(f"ğŸ“¥ å·²åŠ è½½ {len(raw_texts)} æ¡åŸå§‹æ•°æ®")

        print("\n=== é˜¶æ®µ2ï¼šç”Ÿæˆæ¨¡å‹è®­ç»ƒ ===")
        system._train_generative_model(raw_texts)

        print("\n=== é˜¶æ®µ3ï¼šæ¦‚ç‡æ ‡ç­¾ç”Ÿæˆ ===")
        probs = system._generate_probs()
        print(f"ğŸ”– å·²ç”Ÿæˆ {probs.shape[0]} æ¡æ¦‚ç‡æ ‡ç­¾")

        print("\n=== é˜¶æ®µ4ï¼šåˆå§‹æ ‡æ³¨ç”Ÿæˆ ===")
        system.samples = [{
            'text': text,
            'labels': [list(CONFIG["label_rules"].keys())[np.argmax(p)]],
            'prob': max(p)
        } for text, p in zip(raw_texts, probs)]
        print("ğŸ–ï¸ åˆå§‹æ ‡æ³¨å®Œæˆ")

        print("\n=== é˜¶æ®µ5ï¼šäººå·¥éªŒè¯ ===")
        system.manual_verification()

        print("\n=== é˜¶æ®µ6ï¼šç»“æœä¿å­˜ ===")
        system._save_output(probs)
        system._show_statistics()
        print("ğŸ‰ å¤„ç†æµç¨‹å®Œæˆï¼")

    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œï¼Œæ­£åœ¨ä¿å­˜å·²éªŒè¯æ•°æ®...")
        system._save_output()
        system._show_statistics()