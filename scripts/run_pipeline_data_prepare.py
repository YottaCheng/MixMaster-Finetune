# /Volumes/Study/prj/scripts/run_pipeline.py
import subprocess
import sys
from pathlib import Path
import json
import os

class EnhancedPipelineRunner:
    def __init__(self):
        # åŠ¨æ€è·å–é¡¹ç›®æ ¹ç›®å½•
        try:
            self.base_dir = Path(__file__).resolve().parent.parent  # å‡è®¾è„šæœ¬åœ¨ scripts/ ç›®å½•
            print(f"âœ… é¡¹ç›®æ ¹ç›®å½•å·²è‡ªåŠ¨è¯†åˆ«: {self.base_dir}")
        except Exception as e:
            print(f"âŒ æ— æ³•å®šä½é¡¹ç›®æ ¹ç›®å½•: {str(e)}")
            sys.exit(1)

        # åˆå§‹åŒ–è·¯å¾„é…ç½®
        self._init_paths()
        
        # è‡ªåŠ¨åˆ›å»ºå¿…è¦ç›®å½•
        self._create_directories()

    def _init_paths(self):
        """åˆå§‹åŒ–æ‰€æœ‰è·¯å¾„é…ç½®"""
        self.path_config = {
            # è¾“å…¥æ–‡ä»¶
            "input_doc": self.base_dir / "data" / "raw" / "training_raw_data.docx",
            
            # æ­¥éª¤è¾“å‡ºæ–‡ä»¶
            "outputs": {
                "top_words": self.base_dir / "data" / "processed" / "top_20_words.json",
                "synonyms": self.base_dir / "config" / "music_synonyms.json",
                "eda_results": self.base_dir / "data" / "processed" / "augmented_results.docx",
                "backtrans_results": self.base_dir / "data" / "processed" / "backtrans_results.docx"
            },
            
            # å¤„ç†è„šæœ¬è·¯å¾„
            "scripts": {
                "generate_wordcloud": self.base_dir / "scripts" / "data_prepare" / "generate_wordcloud.py",
                "renew_json": self.base_dir / "scripts" / "data_prepare" / "renew_json.py",
                "pure_eda": self.base_dir / "scripts" / "data_prepare" / "pure_eda.py",
                "backtracking": self.base_dir / "scripts" / "data_prepare" / "backtracking.py",
                #"clean_data": self.base_dir / "scripts" / "data_prepare" / "clean_data.py"
            }
        }

    def _create_directories(self):
        """è‡ªåŠ¨åˆ›å»ºç¼ºå¤±ç›®å½•"""
        required_dirs = [
            self.base_dir / "data" / "raw",
            self.base_dir / "data" / "processed",
            self.base_dir / "config",
            self.base_dir / "scripts" / "data_prepare"
        ]
        
        for directory in required_dirs:
            try:
                directory.mkdir(parents=True, exist_ok=True)
                print(f"ğŸ“‚ å·²åˆ›å»º/ç¡®è®¤ç›®å½•: {directory.relative_to(self.base_dir)}")
            except Exception as e:
                print(f"âŒ ç›®å½•åˆ›å»ºå¤±è´¥: {directory} - {str(e)}")
                sys.exit(1)

    def _validate_inputs(self):
        """éªŒè¯è¾“å…¥æ–‡ä»¶å­˜åœ¨"""
        missing = []
        print("\nğŸ” è¾“å…¥æ–‡ä»¶éªŒè¯ï¼š")
        
        # æ£€æŸ¥åŸå§‹æ•°æ®æ–‡ä»¶
        input_doc = self.path_config["input_doc"]
        status = "âœ… å­˜åœ¨" if input_doc.exists() else "âŒ ç¼ºå¤±"
        print(f"è®­ç»ƒæ•°æ®æ–‡ä»¶".ljust(20) + f" | {status} | {input_doc.relative_to(self.base_dir)}")
        
        if not input_doc.exists():
            missing.append(input_doc)
        
        # æ£€æŸ¥è„šæœ¬æ–‡ä»¶
        print("\nğŸ”§ è„šæœ¬æ–‡ä»¶éªŒè¯ï¼š")
        for script_name, script_path in self.path_config["scripts"].items():
            status = "âœ… å­˜åœ¨" if script_path.exists() else "âŒ ç¼ºå¤±"
            print(f"{script_name.ljust(20)} | {status} | {script_path.relative_to(self.base_dir)}")
            if not script_path.exists():
                missing.append(script_path)
        
        if missing:
            print(f"\nâŒ ç¼ºå¤± {len(missing)} ä¸ªå…³é”®æ–‡ä»¶ï¼š")
            for path in missing:
                print(f"  - {path.relative_to(self.base_dir)}")
            sys.exit(1)

    def _run_pipeline_step(self, step: dict) -> bool:
        """æ‰§è¡Œå•ä¸ªæµæ°´çº¿æ­¥éª¤"""
        env = os.environ.copy()
        env["PYTHONUNBUFFERED"] = "1" 
        try:
            print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œ: {step['name']}")
            print("â”" * 50)
            
            # æ˜¾ç¤ºå®Œæ•´å‘½ä»¤
            cmd_str = " ".join(str(arg) for arg in step["command"])
            print(f"æ‰§è¡Œå‘½ä»¤: {cmd_str}")
            
            result = subprocess.run(
                step["command"],
                check=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding='utf-8'
            )
            print("è¾“å‡ºæ—¥å¿—:")
            print(result.stdout)
            print("é”™è¯¯æ—¥å¿—:")  # æ–°å¢ï¼šæ˜¾å¼æ‰“å°é”™è¯¯æ—¥å¿—
            print(result.stderr)  # ç¡®ä¿ stderr è¢«æ•è·
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            missing_outputs = [f for f in step["outputs"] if not f.exists()]
            if missing_outputs:
                print(f"âš ï¸ æœªç”Ÿæˆé¢„æœŸè¾“å‡ºæ–‡ä»¶:")
                for f in missing_outputs:
                    print(f"  - {f.relative_to(self.base_dir)}")
                return False
                
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"""
            âŒ æ‰§è¡Œå¤±è´¥: {step['name']}
            é”™è¯¯ä»£ç : {e.returncode}
            é”™è¯¯è¯¦æƒ…:
            {e.stderr.strip() or 'æ— é¢å¤–é”™è¯¯ä¿¡æ¯'}
            """)
            return False
        except FileNotFoundError:
            print(f"""
            âŒ æ‰¾ä¸åˆ°è„šæœ¬æ–‡ä»¶: {step['command'][1]}
            é¢„æœŸè·¯å¾„: {step['command'][1]}
            å®é™…è·¯å¾„: {Path(step['command'][1]).resolve() if Path(step['command'][1]).exists() else 'æ–‡ä»¶ä¸å­˜åœ¨'}
            """)
            return False

    def _get_pipeline_steps(self):
        """å®šä¹‰æµæ°´çº¿æ­¥éª¤"""
        return [
            {
                "name": "ç”Ÿæˆè¯äº‘æ•°æ®",
                "command": [
                    sys.executable,
                    str(self.path_config["scripts"]["generate_wordcloud"]),
                    "--input", str(self.path_config["input_doc"]),
                    "--output", str(self.path_config["outputs"]["top_words"])
                ],
                "outputs": [self.path_config["outputs"]["top_words"]],
                "troubleshooting": [
                    "ç¡®è®¤è¾“å…¥æ–‡ä»¶åŒ…å«æœ‰æ•ˆæ–‡æœ¬å†…å®¹",
                    "æ£€æŸ¥Pythonç¯å¢ƒä¾èµ–æ˜¯å¦å®‰è£…"
                ]
            },
            {
                "name": "ç”Ÿæˆæ›¿æ¢è¯å…¸",
                "command": [
                    sys.executable,
                    str(self.path_config["scripts"]["renew_json"]),
                    "--input", str(self.path_config["outputs"]["top_words"]),
                    "--output", str(self.path_config["outputs"]["synonyms"])
                ],
                "outputs": [self.path_config["outputs"]["synonyms"]],
                "troubleshooting": [
                    "ç¡®è®¤è¯äº‘æ–‡ä»¶æ ¼å¼æ­£ç¡®",
                    "æ£€æŸ¥JSONå†™å…¥æƒé™"
                ]
            },
            {
                "name": "æ‰§è¡ŒEDAå¢å¼º",
                "command": [
                    sys.executable,
                    str(self.path_config["scripts"]["pure_eda"]),
                    "--input", str(self.path_config["input_doc"]),
                    "--config", str(self.path_config["outputs"]["synonyms"]),
                    "--output", str(self.path_config["outputs"]["eda_results"])
                ],
                "outputs": [self.path_config["outputs"]["eda_results"]],
                "troubleshooting": [
                    "éªŒè¯åŒä¹‰è¯è¯å…¸æ ¼å¼",
                    "æ£€æŸ¥è¾“å‡ºç›®å½•å†™å…¥æƒé™"
                ]
            },
            {
                "name": "æ‰§è¡Œå›è¯‘å¢å¼º",
                "command": [
                    sys.executable,
                    str(self.path_config["scripts"]["backtracking"]),
                    "--input", str(self.path_config["input_doc"]),
                    "--output", str(self.path_config["outputs"]["backtrans_results"])
                ],
                "outputs": [self.path_config["outputs"]["backtrans_results"]],
                "troubleshooting": [
                    "ç¡®è®¤ç¿»è¯‘APIå¯†é’¥æœ‰æ•ˆ",
                    "æ£€æŸ¥ç½‘ç»œè¿æ¥"
                ]
            }
        ]

    def run(self):
        print("\n" + "="*50)
        print("ğŸš€ å¯åŠ¨éŸ³ä¹æ•°æ®å¤„ç†æµæ°´çº¿")
        print("="*50)
        
        # å‰ç½®æ£€æŸ¥
        self._validate_inputs()
        
        # æ‰§è¡Œæµæ°´çº¿
        total_steps = len(self._get_pipeline_steps())
        for step_num, step_config in enumerate(self._get_pipeline_steps(), 1):
            print(f"\nğŸ”§ æ­£åœ¨æ‰§è¡Œæ­¥éª¤ {step_num}/{total_steps}")
            success = self._run_pipeline_step(step_config)
            
            if not success:
                print("\n" + "!"*50)
                print(f"âŒ æµæ°´çº¿åœ¨æ­¥éª¤ [{step_config['name']}] å¤±è´¥")
                print("å»ºè®®æ’æŸ¥æ­¥éª¤:")
                for tip in step_config.get("troubleshooting", []):
                    print(f"  - {tip}")
                sys.exit(1)
        
        # æœ€ç»ˆéªŒè¯
        print("\n" + "="*50)
        print("ğŸ” æœ€ç»ˆè¾“å‡ºéªŒè¯")
        all_outputs = [
            self.path_config["outputs"]["top_words"],
            self.path_config["outputs"]["synonyms"],
            self.path_config["outputs"]["eda_results"],
            self.path_config["outputs"]["backtrans_results"]
        ]
        
        missing = [f for f in all_outputs if not f.exists()]
        if missing:
            print(f"âš ï¸ ç¼ºå¤± {len(missing)} ä¸ªè¾“å‡ºæ–‡ä»¶:")
            for f in missing:
                print(f"  - {f.relative_to(self.base_dir)}")
            sys.exit(1)
        
        print("\n" + "âœ…"*3 + " æµæ°´çº¿æ‰§è¡ŒæˆåŠŸ " + "âœ…"*3)
        print(f"ç”Ÿæˆæ–‡ä»¶ä½ç½®: {self.base_dir/'data'/'processed'}")
        print(f"æ€»ç”Ÿæˆæ–‡ä»¶æ•°: {len(all_outputs)}")
        print("="*50)

if __name__ == "__main__":
    EnhancedPipelineRunner().run()