import sys
import os
import dashscope
from dashscope import Generation
import streamlit as st
import time

# ---------- è®¾ç½®é¡µé¢é…ç½® ----------
st.set_page_config(
    page_title="Mix Master",
    page_icon="ğŸšï¸",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ---------- åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ ----------
if "lang" not in st.session_state:
    st.session_state.lang = "English"
if "run_analysis" not in st.session_state:
    st.session_state.run_analysis = False
if "model_loaded" not in st.session_state:
    st.session_state.model_loaded = False
if "custom_model_path" not in st.session_state:
    st.session_state.custom_model_path = ""
if "show_model_selector" not in st.session_state:
    st.session_state.show_model_selector = False
if "using_mock_predictor" not in st.session_state:
    st.session_state.using_mock_predictor = False

# ---------- æ·»åŠ å½“å‰ç›®å½•åˆ°å¯¼å…¥è·¯å¾„ ----------
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)  # ç¡®ä¿ä¼˜å…ˆæœç´¢å½“å‰ç›®å½•

# ---------- è¯­è¨€é…ç½® ----------
lang = st.session_state.get("lang", "English")

# ---------- ç•Œé¢æ–‡æœ¬é…ç½® ----------
UI_TEXTS = {
    "ä¸­æ–‡": {
        "title": "ğŸšï¸ Mix Master",
        "subtitle": "ä¸“ä¸šéŸ³é¢‘å¤„ç†åŠ©æ‰‹",
        "input_label": "è¯·è¾“å…¥éŸ³é¢‘å¤„ç†éœ€æ±‚ï¼ˆä¸­è‹±æ–‡å‡å¯ï¼‰",
        "output_label": "é¢„æµ‹æ ‡ç­¾",
        "output_code": "æ ‡ç­¾ä»£ç ",
        "advice_title": "æ··éŸ³å»ºè®®",
        "edit_hint": "å¯ç›´æ¥ç¼–è¾‘æ­¤æ–‡æœ¬",
        "copy_btn": "ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿",
        "copy_success": "âœ… å·²å¤åˆ¶",
        "paste_placeholder": "[ç²˜è´´å†…å®¹å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ]",
        "paste_btn": "ğŸ“ æ‰‹åŠ¨ç²˜è´´",
        "clear_btn": "ğŸ§¹ æ¸…ç©º",
        "analyze_btn": "ğŸš€ å¼€å§‹åˆ†æ",
        "switch_lang": "ğŸŒ switch to Eng",
        "examples_title": "ğŸ’¡ ç¤ºä¾‹è¾“å…¥",
        "examples": [
            "äººå£°é«˜é¢‘éœ€è¦æ›´æ˜äº®",
            "å¢åŠ é¼“ç»„çš„å†²å‡»åŠ›",
            "æ•´ä½“ç©ºé—´æ„Ÿä¸è¶³"
        ],
        "error_msg": "âš ï¸ é¢„æµ‹å¤±è´¥ï¼š",
        "generating": "æ­£åœ¨ç”Ÿæˆæ··éŸ³å»ºè®®...",
        "api_error": "âš ï¸ ç”Ÿæˆå»ºè®®å¤±è´¥ï¼š",
        "paste_toolbox": "å¤åˆ¶/ç²˜è´´å·¥å…·ç®±",
        "toolbox_title": "å·¥å…·ç®±",
        "footer": "Â© 2025 E.Stay Mix Master | ä¸“ä¸šéŸ³é¢‘è§£å†³æ–¹æ¡ˆ",
        "powered_by": "åŸºäºäººå·¥æ™ºèƒ½æŠ€æœ¯",
        "input_section": "è¾“å…¥éœ€æ±‚",
        "output_section": "åˆ†æç»“æœ",
        "advice_section": "æ··éŸ³å»ºè®®",
        "examples_section": "ç¤ºä¾‹è¾“å…¥", 
        "advice_placeholder": "ç‚¹å‡»'å¼€å§‹åˆ†æ'ç”Ÿæˆæ··éŸ³å»ºè®®...",
        # æ–°å¢ç¿»è¯‘
        "model_settings": "æ¨¡å‹è®¾ç½®",
        "default_model_path": "é»˜è®¤æ¨¡å‹è·¯å¾„",
        "custom_model_path": "è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„",
        "use_custom_model": "ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹",
        "model_select_info": "é»˜è®¤æ¨¡å‹æœªæ‰¾åˆ°ï¼Œè¯·æŒ‡å®šè‡ªå®šä¹‰æ¨¡å‹è·¯å¾„",
        "model_path_placeholder": "è¯·è¾“å…¥æ¨¡å‹è·¯å¾„...",
        "load_model_btn": "åŠ è½½æ¨¡å‹",
        "model_loaded_success": "âœ… æ¨¡å‹åŠ è½½æˆåŠŸ",
        "model_loaded_error": "âŒ æ¨¡å‹åŠ è½½å¤±è´¥",
        "finetune_guide": "ä½¿ç”¨LlamaFactoryè¿›è¡ŒDeepSeek-R1å¾®è°ƒæŒ‡å—",
        "finetune_steps": [
            "1. å…‹éš†LlamaFactory: git clone https://github.com/hiyouga/LLaMA-Factory.git",
            "2. å‡†å¤‡æ•°æ®é›†: å°† /Volumes/Study/prj/data/llama_factory/alpaca_data.json å¤åˆ¶åˆ°LlamaFactoryçš„æ•°æ®ç›®å½•",
            "3. ä½¿ç”¨é…ç½®: å°† /Volumes/Study/prj/config ä¸­çš„YAMLå¤åˆ¶åˆ°LlamaFactory",
            "4.æ‰§è¡Œå¾®è°ƒ: ä½¿ç”¨LlamaFactoryè‡ªåŠ¨å¾®è°ƒdeepseek-ai/DeepSeek-R1-Distill-Qwen-1.5Bæ¨¡å‹",
            "5. è‡ªåŠ¨å°†å¾®è°ƒåçš„æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šè¾“å‡ºç›®å½•"],
        "show_finetune_guide": "æ˜¾ç¤ºå¾®è°ƒæŒ‡å—",
        "hide_finetune_guide": "éšè—å¾®è°ƒæŒ‡å—",
        "select_model_path": "é€‰æ‹©æ¨¡å‹è·¯å¾„",
        "using_mock_predictor": "âš ï¸ å½“å‰ä½¿ç”¨æ¨¡æ‹Ÿé¢„æµ‹å™¨ï¼Œé¢„æµ‹ç»“æœå¯èƒ½ä¸å‡†ç¡®",
        "mock_predictor_note": "æ¨¡æ‹Ÿé¢„æµ‹å™¨ä¸éœ€è¦æ¨¡å‹æƒé‡ï¼Œå¯ç”¨äºæ¼”ç¤º",
        "use_mock_predictor": "ä½¿ç”¨æ¨¡æ‹Ÿé¢„æµ‹å™¨"
    },
    "English": {
        "title": "ğŸšï¸ Mix Master",
        "subtitle": "Professional Audio Processing Assistant",
        "input_label": "Enter audio processing request (Chinese/English)",
        "output_label": "Predicted Label",
        "output_code": "Label Code",
        "advice_title": "Mixing Advice",
        "edit_hint": "You can edit this text directly",
        "copy_btn": "ğŸ“‹ Copy to Clipboard",
        "copy_success": "âœ… Copied",
        "paste_placeholder": "[Pasted content will appear here]",
        "paste_btn": "ğŸ“ Manual Paste", 
        "clear_btn": "ğŸ§¹ Clear",
        "analyze_btn": "ğŸš€ Analyze",
        "switch_lang": "ğŸŒ Switch to Chinese",
        "examples_title": "ğŸ’¡ Example Inputs",
        "examples": [
            "Vocals need more brightness",
            "Increase drum punchiness",
            "Lack of overall spatial depth"
        ],
        "error_msg": "âš ï¸ Prediction failed: ",
        "generating": "Generating mixing advice...",
        "api_error": "âš ï¸ Failed to generate advice: ",
        "paste_toolbox": "Copy/Paste Toolbox",
        "toolbox_title": "Toolbox",
        "footer": "Â© 2025 E.Stay Mix Master | Professional Audio Solution",
        "powered_by": "Powered by AI Technology",
        "input_section": "Input Request",
        "output_section": "Analysis Results",
        "advice_section": "Mixing Advice",
        "examples_section": "Example Inputs",
        "advice_placeholder": "Click 'Analyze' to generate mixing advice...",
        # New translations
        "model_settings": "Model Settings",
        "default_model_path": "Default Model Path",
        "custom_model_path": "Custom Model Path",
        "use_custom_model": "Use Custom Model",
        "model_select_info": "Default model not found. Please specify a custom model path",
        "model_path_placeholder": "Enter model path...",
        "load_model_btn": "Load Model",
        "model_loaded_success": "âœ… Model loaded successfully",
        "model_loaded_error": "âŒ Failed to load model",
        "finetune_guide": "LlamaFactory Fine-tuning Guide with DeepSeek-R1",
        "finetune_steps": [
            "1. Clone LlamaFactory: git clone https://github.com/hiyouga/LLaMA-Factory.git",
            "2. Prepare dataset: Copy /Study/prj/data/llama_factory/alpaca_data.json to LlamaFactory's data directory",
            "3. Use configuration: Copy YAML from /Volumes/Study/prj/config to LlamaFactory",
            "4. Execute fine-tuning: Use LlamaFactory's automated fine-tuning on deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
            "5. Automatically save fine-tuned model to specified output directory"
        ],
        "show_finetune_guide": "Show Fine-tuning Guide",
        "hide_finetune_guide": "Hide Fine-tuning Guide",
        "select_model_path": "Select Model Path",
        "using_mock_predictor": "âš ï¸ Currently using mock predictor, predictions may not be accurate",
        "mock_predictor_note": "Mock predictor doesn't require model weights and can be used for demonstration",
        "use_mock_predictor": "Use Mock Predictor"
    }
}

# ---------- APIé…ç½® ----------
dashscope.api_key = "sk-3b986ed51abb4ed18aadde5d41e11397"

# ---------- å¯¼å…¥é¢„æµ‹å™¨ ----------
try:
    from predict import MixingLabelPredictor
    predictor_import_success = True
except ImportError as e:
    st.error(f"å¯¼å…¥ MixingLabelPredictor å¤±è´¥: {str(e)}")
    predictor_import_success = False

# ---------- åˆ›å»ºæ¨¡æ‹Ÿé¢„æµ‹å™¨ç±» ----------
class MockMixingLabelPredictor:
    def predict(self, text, lang):
        if lang == "ä¸­æ–‡":
            return "é«˜é¢‘æå‡", "å£°éŸ³ç©ºé—´æ„Ÿ", "HF001"
        else:
            return "High Frequency Enhancement", "Spatial Depth", "HF001"

# ---------- è®¾ç½®è‡ªå®šä¹‰CSSæ ·å¼ ----------
def set_custom_css():
    st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

    /* ä¸»è¦æ ·å¼å˜é‡ */
    :root {
        --primary-color: #7c3aed;
        --primary-light: #a78bfa;
        --primary-dark: #6d28d9;
        --primary-gradient: linear-gradient(135deg, #7c3aed, #5b21b6);
        
        --bg-color: #f8fafc;
        --card-bg: #ffffff;
        --card-secondary-bg: #f1f5f9;
        
        --text-color: #1e293b;
        --text-secondary: #64748b;
        --text-muted: #94a3b8;
        
        --border-color: #e2e8f0;
        --radius-md: 10px;
    }

    /* ä¸»æ ·å¼ */
    .stApp {
        background-color: var(--bg-color);
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    }

    /* æ ‡é¢˜æ ·å¼ */
    .app-title {
        font-family: 'Inter', sans-serif;
        font-weight: 700;
        font-size: 26px;
        margin-bottom: 0;
        color: var(--text-color);
        position: relative;
        display: inline-block;
    }
    
    .app-title::after {
        content: "";
        position: absolute;
        bottom: -5px;
        left: 0;
        width: 40px;
        height: 3px;
        background: var(--primary-gradient);
        border-radius: 10px;
    }
    
    .app-subtitle {
        font-family: 'Inter', sans-serif;
        font-size: 15px;
        color: var(--text-secondary);
        margin-top: 10px;
        margin-bottom: 20px;
    }

    /* åŒºå—æ ‡é¢˜æ ·å¼ */
    .section-title {
        font-family: 'Inter', sans-serif;
        font-size: 17px;
        font-weight: 600;
        color: var(--text-color);
        margin-top: 20px;
        margin-bottom: 10px;
        padding-left: 10px;
        border-left: 4px solid var(--primary-color);
        line-height: 1.2;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    div[data-testid="stButton"] > button, div[data-testid="stDownloadButton"] > button {
        font-family: 'Inter', sans-serif;
        font-weight: 500;
        border-radius: var(--radius-md);
        transition: all 0.2s ease;
    }
    
    div[data-testid="stButton"] > button[kind="primary"] {
        background: var(--primary-gradient);
        border: none;
    }
    
    div[data-testid="stButton"] > button:hover {
        transform: translateY(-1px);
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* ç¤ºä¾‹æŒ‰é’®æ ·å¼ */
    .example-button {
        background-color: var(--card-secondary-bg);
        border: 1px solid var(--border-color);
        border-radius: var(--radius-md);
        padding: 8px 12px;
        margin-right: 8px;
        margin-bottom: 8px;
        cursor: pointer;
        transition: all 0.2s;
        font-size: 14px;
        display: inline-block;
    }
    
    .example-button:hover {
        background-color: white;
        border-color: var(--primary-color);
        transform: translateY(-1px);
    }
    
    /* å¡ç‰‡å’Œå®¹å™¨æ ·å¼ */
    .output-container {
        background-color: var(--card-bg);
        border: 1px solid var(--border-color);
        border-radius: var(--radius-md);
        padding: 15px;
        margin: 10px 0;
    }
    
    /* é¡µè„šæ ·å¼ */
    .footer {
        text-align: center;
        font-size: 13px;
        color: var(--text-muted);
        margin-top: 40px;
        padding-top: 20px;
        border-top: 1px solid var(--border-color);
    }
    
    /* æ–‡æœ¬è¾“å…¥æ¡†æ ·å¼ */
    div[data-baseweb="textarea"] textarea, div[data-baseweb="input"] input {
        font-family: 'Inter', sans-serif;
    }
    
    /* å·¥å…·ç®±æ ·å¼ */
    .toolbox {
        margin-top: 30px;
    }
    
    /* æç¤ºæ–‡æœ¬æ ·å¼ */
    .stCaption {
        color: var(--text-muted);
        font-size: 13px;
        font-style: italic;
        text-align: right;
    }
    
    /* ä¿®æ”¹æ»‘åŠ¨æ¡æ ·å¼ */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    ::-webkit-scrollbar-track {
        background: var(--card-bg);
    }
    ::-webkit-scrollbar-thumb {
        background: var(--border-color);
        border-radius: 10px;
    }
    ::-webkit-scrollbar-thumb:hover {
        background: var(--primary-dark);
    }
    
    /* é’ˆå¯¹ç§»åŠ¨ç«¯çš„å“åº”å¼è°ƒæ•´ */
    @media (max-width: 768px) {
        .app-title {
            font-size: 22px;
        }
        
        .app-subtitle {
            font-size: 14px;
        }
        
        .section-title {
            font-size: 16px;
        }
    }
    
    /* æ¨¡å‹é€‰æ‹©å™¨æ ·å¼ */
    .model-selector {
        background-color: var(--card-bg);
        border: 1px solid var(--border-color);
        border-radius: var(--radius-md);
        padding: 15px;
        margin: 20px 0;
    }
    
    /* æŒ‡å—æ ·å¼ */
    .guide-container {
        background-color: var(--card-secondary-bg);
        border: 1px solid var(--border-color);
        border-radius: var(--radius-md);
        padding: 15px;
        margin: 10px 0;
    }
    
    .guide-step {
        margin-bottom: 8px;
        font-size: 14px;
    }
    
    /* è­¦å‘Šä¿¡æ¯æ ·å¼ */
    .warning-box {
        background-color: #fff9c4;
        border: 1px solid #fbc02d;
        border-radius: var(--radius-md);
        padding: 10px 15px;
        margin: 10px 0;
        color: #7c4d00;
    }
    </style>
    """, unsafe_allow_html=True)

# ---------- åŠ è½½æ¨¡å‹ ----------
@st.cache_resource
def load_predictor(model_dir=None, force_reload=False):
    """åŠ è½½é¢„æµ‹å™¨æ¨¡å‹ï¼Œé»˜è®¤æ¨¡å‹æˆ–è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„"""
    # è·å–è¯­è¨€
    lang = st.session_state.lang
    
    # å¦‚æœæœªæŒ‡å®šæ¨¡å‹è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    if model_dir is None:
        model_dir = r"D:\kings\prj\Finetune_local\Models\deepseek_R1_MixMaster\v6"
    
    # åˆ¤æ–­æ˜¯å¦å­˜åœ¨æ¨¡å‹ç›®å½•
    if not os.path.exists(model_dir):
        st.warning(UI_TEXTS[lang]["model_select_info"])
        st.session_state.show_model_selector = True
        return None

    try:
        print(f"åŠ è½½æ¨¡å‹ä¸­...è·¯å¾„: {model_dir}")
        predictor = MixingLabelPredictor(model_dir=model_dir)
        st.success(UI_TEXTS[lang]["model_loaded_success"])
        st.session_state.model_loaded = True
        return predictor
    except Exception as e:
        st.error(f"{UI_TEXTS[lang]['model_loaded_error']}: {str(e)}")
        st.session_state.show_model_selector = True
        return None

# ---------- æ ¸å¿ƒé€»è¾‘ ----------
def get_mixing_advice(user_input, label, lang="ä¸­æ–‡"):
    """è°ƒç”¨DashScope APIç”Ÿæˆæ··éŸ³å»ºè®®"""
    try:
        # æ„å»ºæç¤ºè¯
        if lang == "ä¸­æ–‡":
            prompt = f"""
æˆ‘æ˜¯ä¸€ä½ä¸“ä¸šçš„éŸ³é¢‘æ··éŸ³å·¥ç¨‹å¸ˆã€‚æˆ‘æƒ³è¦å®ç°ä»¥ä¸‹æ•ˆæœï¼š"{user_input}"
æ ¹æ®åˆ†æï¼Œè¿™å±äº"{label}"ç±»å‹çš„å¤„ç†éœ€æ±‚ã€‚

è¯·ç»™å‡ºç®€çŸ­çš„æ··éŸ³å»ºè®®ï¼Œä»‹ç»å¦‚ä½•è°ƒæ•´éŸ³é¢‘å‚æ•°å®ç°è¿™ä¸ªæ•ˆæœã€‚
ä¸è¦æåŠå…·ä½“çš„æ’ä»¶åç§°ï¼Œä¹Ÿä¸è¦ç»™å‡ºå…·ä½“çš„æ•°å€¼å‚æ•°ï¼Œåªéœ€æä¾›è°ƒæ•´æ–¹å‘å’ŒæŠ€æœ¯æ€è·¯ã€‚
å»ºè®®åº”ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡3-4å¥è¯ã€‚ç”¨ä¸­æ–‡å›ç­”ã€‚
"""
        else:
            prompt = f"""
I am a professional audio mixing engineer. I want to achieve the following effect: "{user_input}"
Based on analysis, this belongs to the "{label}" type of processing requirement.

Please provide brief mixing advice on how to adjust audio parameters to achieve this effect.
Do not mention specific plugin names, and do not provide specific numerical parameters, just provide adjustment directions and technical approach.
The advice should be concise, no more than 3-4 sentences. Answer in English.
"""

        # æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
        progress_placeholder = st.empty()
        progress_placeholder.markdown(f"**{UI_TEXTS[lang]['generating']}**")
        
        try:
            # è°ƒç”¨DashScope API - å°è¯•æµå¼å“åº”
            response = Generation.call(
                model="qwq-plus-2025-03-05",
                messages=[{"role": "user", "content": prompt}],
                stream=True,
                incremental_output=True,
                result_format="message",
                temperature=0.2,
                top_p=0.7,
                max_tokens=150
            )
            
            # è§£ææµå¼å“åº”
            full_response = []
            progress_text = ""
            
            for chunk in response:
                if chunk.status_code == 200:
                    if hasattr(chunk.output, 'choices') and len(chunk.output.choices) > 0:
                        message = chunk.output.choices[0].get('message')
                        if message and 'content' in message:
                            content = message['content']
                            full_response.append(content)
                            progress_text += content
                            progress_placeholder.markdown(f"**{UI_TEXTS[lang]['generating']}**\n\n{progress_text}")
                else:
                    progress_placeholder.empty()
                    return f"{UI_TEXTS[lang]['api_error']} é”™è¯¯ç  {chunk.status_code}"
            
            progress_placeholder.empty()
            return ''.join(full_response).strip()
            
        except Exception as stream_error:
            # å¦‚æœæµå¼å“åº”å¤±è´¥ï¼Œå›é€€åˆ°éæµå¼å“åº”
            try:
                # éæµå¼å“åº”
                response = Generation.call(
                    model="qwq-plus-2025-03-05",
                    messages=[{"role": "user", "content": prompt}],
                    stream=False,
                    result_format="message",
                    temperature=0.2,
                    top_p=0.7,
                    max_tokens=150
                )
                
                progress_placeholder.empty()
                
                # è§£æéæµå¼å“åº”
                if response.status_code == 200:
                    if hasattr(response.output, 'choices') and len(response.output.choices) > 0:
                        message = response.output.choices[0].get('message')
                        if message and 'content' in message:
                            return message['content'].strip()
                
                return f"{UI_TEXTS[lang]['api_error']} é”™è¯¯ç  {response.status_code}"
            
            except Exception as e:
                progress_placeholder.empty()
                return f"{UI_TEXTS[lang]['api_error']} {str(e)}"
            
    except Exception as e:
        return f"{UI_TEXTS[lang]['api_error']}{str(e)}"

def predict_wrapper(predictor, text, lang):
    """é¢„æµ‹å‡½æ•°åŒ…è£…å™¨ï¼Œæ¥æ”¶predictorä½œä¸ºå‚æ•°"""
    try:
        # è·å–é¢„æµ‹ç»“æœï¼Œå§‹ç»ˆåŒæ—¶è·å–ä¸­è‹±æ–‡ç»“æœ
        zh_main, zh_secondary, code = predictor.predict(text, "ä¸­æ–‡")
        en_main, en_secondary, _ = predictor.predict(text, "English")
        
        # è·å–æ··éŸ³å»ºè®®
        advice = get_mixing_advice(
            text, 
            zh_main if lang == "ä¸­æ–‡" else en_main, 
            lang
        )
        
        # æ ¹æ®è¯­è¨€é€‰æ‹©å±•ç¤ºæ–¹å¼
        if lang == "ä¸­æ–‡":
            full_label = zh_main
            if zh_secondary:
                full_label += "ï¼Œ" + zh_secondary
            return full_label, code, advice
        else:
            full_label = en_main
            if en_secondary:
                full_label += ", " + en_secondary
            return full_label, code, advice
    except Exception as e:
        error_msg = f"{UI_TEXTS[lang]['error_msg']}{str(e)}"
        return error_msg, "ERROR", ""

# ---------- åˆ›å»ºæ ‡é¢˜å’Œå‰¯æ ‡é¢˜ ----------
def render_header():
    lang = st.session_state.get("lang", "English")
    st.markdown(f'<h1 class="app-title">{UI_TEXTS[lang]["title"]}</h1>', unsafe_allow_html=True)
    st.markdown(f'<p class="app-subtitle">{UI_TEXTS[lang]["subtitle"]}</p>', unsafe_allow_html=True)

# ---------- åˆ›å»ºæ¨¡å‹é€‰æ‹©å™¨ ----------
# ---------- åˆ›å»ºæ¨¡å‹é€‰æ‹©å™¨ ----------
def render_model_selector(key=None):
    lang = st.session_state.get("lang", "English")
    
    with st.expander(UI_TEXTS[lang]["model_settings"], expanded=st.session_state.show_model_selector):
        st.markdown(f'<div class="model-selector">', unsafe_allow_html=True)
        
        # é»˜è®¤æ¨¡å‹è·¯å¾„
        default_model_path = r"D:\kings\prj\Finetune_local\Models\deepseek_R1_MixMaster\v6"
        st.text_input(
            UI_TEXTS[lang]["default_model_path"], 
            value=default_model_path, 
            disabled=True,
            key=f"default_model_path_{key}" if key else "default_model_path"
        )
        
        # è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„
        custom_model_path = st.text_input(
            UI_TEXTS[lang]["custom_model_path"], 
            value=st.session_state.custom_model_path,
            placeholder=UI_TEXTS[lang]["model_path_placeholder"],
            key=f"custom_model_path_input_{key}" if key else "custom_model_path_input"
        )
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        st.session_state.custom_model_path = custom_model_path
        
        # æ¨¡æ‹Ÿé¢„æµ‹å™¨é€‰é¡¹
        use_mock = st.checkbox(
            UI_TEXTS[lang]["use_mock_predictor"], 
            value=False, 
            key=f"use_mock_predictor_{key}" if key else "use_mock_predictor"
        )
        if use_mock:
            st.markdown(f'<div class="warning-box">{UI_TEXTS[lang]["mock_predictor_note"]}</div>', unsafe_allow_html=True)
        
        # åŠ è½½æ¨¡å‹æŒ‰é’®
        col1, col2 = st.columns(2)
        with col1:
            if st.button(
                UI_TEXTS[lang]["load_model_btn"], 
                key=f"load_model_button_{key}" if key else "load_model_button"
            ):
                if use_mock:
                    # ä½¿ç”¨æ¨¡æ‹Ÿé¢„æµ‹å™¨
                    st.session_state.predictor = MockMixingLabelPredictor()
                    st.session_state.model_loaded = True
                    st.session_state.using_mock_predictor = True
                    st.success(UI_TEXTS[lang]["model_loaded_success"] + " (Mock)")
                    st.session_state.show_model_selector = False
                    st.rerun()
                elif st.session_state.custom_model_path and os.path.exists(st.session_state.custom_model_path):
                    # åŠ è½½è‡ªå®šä¹‰æ¨¡å‹
                    st.session_state.predictor = load_predictor(model_dir=st.session_state.custom_model_path, force_reload=True)
                    if st.session_state.predictor:
                        st.session_state.using_mock_predictor = False
                        st.session_state.show_model_selector = False
                        st.rerun()
                else:
                    st.error(f"{UI_TEXTS[lang]['error_msg']} {UI_TEXTS[lang]['model_path_placeholder']}")
        
        # å¾®è°ƒæŒ‡å—
        if "show_finetune_guide" not in st.session_state:
            st.session_state.show_finetune_guide = False
        
        guide_button_text = UI_TEXTS[lang]["hide_finetune_guide"] if st.session_state.show_finetune_guide else UI_TEXTS[lang]["show_finetune_guide"]
        
        with col2:
            if st.button(
                guide_button_text, 
                key=f"finetune_guide_button_{key}" if key else "finetune_guide_button"
            ):
                st.session_state.show_finetune_guide = not st.session_state.show_finetune_guide
                st.rerun()
        
        if st.session_state.show_finetune_guide:
            st.markdown(f'<div class="guide-container">', unsafe_allow_html=True)
            st.markdown(f"### {UI_TEXTS[lang]['finetune_guide']}")
            
            for step in UI_TEXTS[lang]["finetune_steps"]:
                st.markdown(f'<div class="guide-step">{step}</div>', unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown('</div>', unsafe_allow_html=True)

# ---------- åˆ›å»ºè¾“å‡ºéƒ¨åˆ† ----------
def render_output_section():
    lang = st.session_state.get("lang", "English")
    
    # è·å–é¢„æµ‹ç»“æœ
    prediction_label = st.session_state.get("prediction_label", "")
    prediction_code = st.session_state.get("prediction_code", "")
    advice = st.session_state.get("advice", "")
    
    # åªæœ‰å½“æœ‰é¢„æµ‹ç»“æœæ—¶æ‰æ˜¾ç¤ºè¾“å‡ºåŒºåŸŸ
    if prediction_label or prediction_code or advice:
        st.markdown(f'<div class="section-title">{UI_TEXTS[lang]["output_section"]}</div>', unsafe_allow_html=True)
        
        # é¢„æµ‹æ ‡ç­¾å’Œä»£ç 
        col1, col2 = st.columns(2)
        with col1:
            st.text_input(UI_TEXTS[lang]["output_label"], value=prediction_label, disabled=True)
        with col2:
            st.text_input(UI_TEXTS[lang]["output_code"], value=prediction_code, disabled=True)
        
        # æ··éŸ³å»ºè®®
        st.markdown(f'<div class="section-title">{UI_TEXTS[lang]["advice_section"]}</div>', unsafe_allow_html=True)
        
        # å¯ç¼–è¾‘å»ºè®®
        edited_advice = st.text_area(
            label="",
            value=advice if advice else UI_TEXTS[lang]["advice_placeholder"],
            height=150,
            key="advice_widget"
        )
        
        # åŒæ­¥ç¼–è¾‘åçš„å»ºè®®
        if edited_advice != advice and advice:
            st.session_state.advice = edited_advice
        
        st.caption(UI_TEXTS[lang]["edit_hint"])
        
        # æ·»åŠ å¤åˆ¶æŒ‰é’®
        if advice:
            copy_clicked = st.button(
                UI_TEXTS[lang]["copy_btn"],
                key="copy_button"
            )
            
            # å¤„ç†å¤åˆ¶äº‹ä»¶
            if copy_clicked:
                # å°†å»ºè®®æ·»åŠ åˆ°å‰ªè´´æ¿åŒºåŸŸ
                st.session_state.clipboard_content = edited_advice
                
                # æ˜¾ç¤ºå¤åˆ¶æˆåŠŸæ¶ˆæ¯
                st.success(UI_TEXTS[lang]["copy_success"])

# ---------- åˆ›å»ºå·¥å…·ç®±éƒ¨åˆ† ----------
def render_toolbox():
    lang = st.session_state.get("lang", "English")
    
    with st.expander(UI_TEXTS[lang]["toolbox_title"]):
        # åˆå§‹åŒ–å‰ªè´´æ¿å†…å®¹
        if "clipboard_content" not in st.session_state:
            st.session_state.clipboard_content = ""
        
        # å‰ªè´´æ¿åŒºåŸŸ
        clipboard_content = st.text_area(
            UI_TEXTS[lang]["paste_btn"],
            value=st.session_state.clipboard_content,
            placeholder=UI_TEXTS[lang]["paste_placeholder"],
            height=100,
            key="clipboard_widget"
        )
        
        # åŒæ­¥å‰ªè´´æ¿å†…å®¹å¹¶è‡ªåŠ¨åº”ç”¨åˆ°è¾“å…¥æ¡†ï¼ˆGradioé£æ ¼ï¼‰
        if st.session_state.get("clipboard_content") != clipboard_content and clipboard_content:
            st.session_state.clipboard_content = clipboard_content
            st.session_state.user_input = clipboard_content
            st.rerun()
        
        st.caption(UI_TEXTS[lang]["edit_hint"])

# ---------- åˆ›å»ºé¡µè„š ----------
def render_footer():
    lang = st.session_state.get("lang", "English")
    
    st.markdown(f"""
    <div class="footer">
        {UI_TEXTS[lang]['footer']}
        <div style="margin-top: 5px; font-size: 12px;">
            {UI_TEXTS[lang]['powered_by']}
        </div>
    </div>
    """, unsafe_allow_html=True)

# ä¸»åº”ç”¨å‡½æ•°


# ---------- åˆ›å»ºç¤ºä¾‹éƒ¨åˆ† ----------
def render_examples():
    lang = st.session_state.get("lang", "English")
    
    st.markdown(f'<div class="section-title">{UI_TEXTS[lang]["examples_section"]}</div>', unsafe_allow_html=True)
    st.markdown(f'<p>{UI_TEXTS[lang]["examples_title"]}</p>', unsafe_allow_html=True)
    
    # ä½¿ç”¨åˆ—å¸ƒå±€åˆ›å»ºç¤ºä¾‹æŒ‰é’®
    cols = st.columns(3)
    for i, example in enumerate(UI_TEXTS[lang]["examples"]):
        with cols[i % 3]:
            if st.button(example, key=f"example_{i}"):
                st.session_state.user_input = example
                st.session_state.run_analysis = True
                st.rerun()

# ---------- åˆ›å»ºè¾“å…¥éƒ¨åˆ† ----------
def render_input_section():
    lang = st.session_state.get("lang", "English")
    
    st.markdown(f'<div class="section-title">{UI_TEXTS[lang]["input_section"]}</div>', unsafe_allow_html=True)
    
    # è®¾ç½®åˆå§‹å€¼
    if "user_input" not in st.session_state:
        st.session_state.user_input = ""
    
    # åˆ›å»ºè¾“å…¥æ¡†
    user_input = st.text_area(
        UI_TEXTS[lang]["input_label"],
        value=st.session_state.user_input,
        height=100,
        placeholder=UI_TEXTS[lang]["examples"][0],
        key="user_input_widget"
    )
    
    # åŒæ­¥è¾“å…¥æ¡†å€¼åˆ°session_state
    st.session_state.user_input = user_input
    
    # åŠŸèƒ½æŒ‰é’®è¡Œ
    cols = st.columns([1, 1, 1])
    
    with cols[0]:
        analyze_clicked = st.button(
            UI_TEXTS[lang]["analyze_btn"],
            type="primary",
            use_container_width=True,
            key="analyze_button"
        )
    
    with cols[1]:
        clear_clicked = st.button(
            UI_TEXTS[lang]["clear_btn"],
            type="secondary",
            use_container_width=True,
            key="clear_button"
        )
    
    with cols[2]:
            lang_clicked = st.button(
                UI_TEXTS[lang]["switch_lang"],
                type="secondary",
                use_container_width=True,
                key="lang_button"
            )
    
    # å¤„ç†æ¸…ç©ºæŒ‰é’®äº‹ä»¶
    if clear_clicked:
        st.session_state.user_input = ""
        st.session_state.prediction_label = ""
        st.session_state.prediction_code = ""
        st.session_state.advice = ""
        st.rerun()
    
    # å¤„ç†è¯­è¨€åˆ‡æ¢äº‹ä»¶
    if lang_clicked:
        st.session_state.lang = "English" if lang == "ä¸­æ–‡" else "ä¸­æ–‡"
        st.rerun()
    
    return user_input, analyze_clicked
def main():
    # åˆå§‹åŒ– predictor åˆ° session_stateï¼ˆå¦‚æœè¿˜æœªåˆå§‹åŒ–ï¼‰
    if 'predictor' not in st.session_state:
        st.session_state.predictor = None
    
    # è®¾ç½®è‡ªå®šä¹‰CSS
    set_custom_css()
    
    # æ¸²æŸ“é¡µé¢ç»„ä»¶
    render_header()
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
    if not st.session_state.model_loaded:
        # å°è¯•åŠ è½½é»˜è®¤æ¨¡å‹
        default_model_path = r"D:\kings\prj\Finetune_local\Models\deepseek_R1_MixMaster\v6"
        st.session_state.predictor = load_predictor(model_dir=default_model_path)
        
        # å¦‚æœé»˜è®¤æ¨¡å‹æ— æ³•åŠ è½½ï¼Œåˆ™æ˜¾ç¤ºæ¨¡å‹é€‰æ‹©å™¨
        if not st.session_state.predictor:
            st.session_state.predictor = MockMixingLabelPredictor()
            st.session_state.using_mock_predictor = True
    
    # åªåœ¨éœ€è¦æ—¶æ¸²æŸ“æ¨¡å‹é€‰æ‹©å™¨
    if st.session_state.show_model_selector:
        # æ·»åŠ ä¸€ä¸ªå”¯ä¸€çš„é”®æ¥åŒºåˆ†ä¸åŒçš„è°ƒç”¨
        render_model_selector(key="main_model_selector")
    
    # å¦‚æœä½¿ç”¨çš„æ˜¯æ¨¡æ‹Ÿé¢„æµ‹å™¨ï¼Œæ˜¾ç¤ºè­¦å‘Š
    if st.session_state.get("using_mock_predictor", False):
        st.markdown(f'<div class="warning-box">{UI_TEXTS[st.session_state.lang]["using_mock_predictor"]}</div>', unsafe_allow_html=True)
    
    # æ¸²æŸ“ç¤ºä¾‹
    render_examples()
    
    # è¾“å…¥åŒºåŸŸ
    user_input, analyze_clicked = render_input_section()
    
    # å¤„ç†åˆ†ææŒ‰é’®äº‹ä»¶
    if (analyze_clicked and user_input) or (st.session_state.run_analysis and st.session_state.user_input):
        # é‡ç½®è¿è¡Œæ ‡å¿—
        st.session_state.run_analysis = False
        
        with st.spinner(UI_TEXTS[st.session_state.lang]["generating"]):
            # æ‰§è¡Œé¢„æµ‹ï¼Œä½¿ç”¨ st.session_state.predictor
            label, code, advice = predict_wrapper(
                st.session_state.predictor, 
                st.session_state.user_input, 
                st.session_state.lang
            )
            
            # ä¿å­˜ç»“æœåˆ°session_state
            st.session_state.prediction_label = label
            st.session_state.prediction_code = code
            st.session_state.advice = advice
    
    # è¾“å‡ºåŒºåŸŸ
    render_output_section()
    
    # å·¥å…·ç®±
    render_toolbox()
    
    # é¡µè„š
    render_footer()

# åº”ç”¨ç¨‹åºå…¥å£
# åº”ç”¨ç¨‹åºå…¥å£
if __name__ == "__main__":
    # åˆå§‹åŒ–å…¨å±€é¢„æµ‹å™¨å˜é‡
    predictor = None
    main()