import os
import torch
import json
from transformers import AutoModelForSequenceClassification, AutoTokenizer

# ---------- ç¿»è¯‘æ¨¡å—ä¾èµ–å¤„ç† ----------
try:
    from deep_translator import GoogleTranslator
except ImportError:
    print("\nâŒ ç¼ºå°‘å¿…è¦ä¾èµ–åŒ…ï¼šdeep-translator")
    print("è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š")
    print("pip install deep-translator")
    print("æˆ–ä½¿ç”¨æ¸…åé•œåƒæºåŠ é€Ÿå®‰è£…ï¼š")
    print("pip install deep-translator -i https://pypi.tuna.tsinghua.edu.cn/simple")
    exit(1)

# ---------- æ··éŸ³æ ‡ç­¾é¢„æµ‹å™¨ ----------
class MixingLabelPredictor:
    def __init__(self, model_dir=r"D:\kings\prj\MixMaster-Finetune\config\Models\deepseek_R1_MixMaster"):
        # éªŒè¯è·¯å¾„
        if not os.path.exists(model_dir):
            raise FileNotFoundError(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
        
        # åŠ è½½æ¨¡å‹ç»„ä»¶
        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
        self.tokenizer = AutoTokenizer.from_pretrained(model_dir)
        
        # åŠ è½½æ ‡ç­¾æ˜ å°„
        self.label_mapping = self._load_label_mapping(
            os.path.join(model_dir, "music_synonyms.json")
        
        # åˆå§‹åŒ–ç¿»è¯‘å™¨
        self.translator = GoogleTranslator(source='zh-CN', target='en')
        
        # è®¾å¤‡é…ç½®
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = self.model.to(self.device)

    def _load_label_mapping(self, path):
        """åŠ è½½æ ‡ç­¾æ˜ å°„æ–‡ä»¶"""
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)

    def _contains_chinese(self, text):
        """ä¸­æ–‡æ£€æµ‹"""
        return any('\u4e00' <= char <= '\u9fff' for char in text)

    def predict(self, input_text, lang="ä¸­æ–‡"):
        """æ‰§è¡Œé¢„æµ‹"""
        try:
            # ç¿»è¯‘å¤„ç†
            if self._contains_chinese(input_text):
                translated_text = self.translator.translate(input_text)
            else:
                translated_text = input_text

            # æ–‡æœ¬ç¼–ç 
            inputs = self.tokenizer(
                translated_text,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors="pt"
            ).to(self.device)

            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                outputs = self.model(**inputs)

            # è·å–é¢„æµ‹ç»“æœ
            predicted_idx = torch.argmax(outputs.logits, dim=1).item()
            return (
                self.label_mapping[str(predicted_idx)]["zh"],
                self.label_mapping[str(predicted_idx)]["en"],
                str(predicted_idx)
        except Exception as e:
            return f"âŒ é¢„æµ‹å¤±è´¥", f"âŒ é”™è¯¯ä»£ç ", str(e)

# ---------- æµ‹è¯•è¿è¡Œ ----------
if __name__ == "__main__":
    try:
        predictor = MixingLabelPredictor()
        test_text = "äººå£°é«˜é¢‘éœ€è¦æ›´æ˜äº®"
        zh_label, en_label, code = predictor.predict(test_text)
        print("\n" + "="*40)
        print(f"ğŸ“¥ è¾“å…¥ï¼š{test_text}")
        print(f"ğŸ‡¨ğŸ‡³ ä¸­æ–‡æ ‡ç­¾ï¼š{zh_label}")
        print(f"ğŸ‡ºğŸ‡¸ è‹±æ–‡æ ‡ç­¾ï¼š{en_label}")
        print(f"ğŸ”¢ æ ‡ç­¾ä»£ç ï¼š{code}")
        print("="*40)
    except Exception as e:
        print(f"\nâŒ åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        print("å¯èƒ½åŸå› ï¼š")
        print("1. æ¨¡å‹æ–‡ä»¶ç¼ºå¤±æˆ–ä¸å®Œæ•´")
        print("2. æ ‡ç­¾æ˜ å°„æ–‡ä»¶æ ¼å¼é”™è¯¯")
        print("3. æœªå®‰è£…å¿…è¦ä¾èµ–ï¼ˆtorch/transformersï¼‰")
        print("è§£å†³æ–¹æ¡ˆï¼š")
        print("pip install torch transformers")